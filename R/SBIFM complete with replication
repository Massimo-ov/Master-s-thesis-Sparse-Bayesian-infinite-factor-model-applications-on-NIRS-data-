Codice implementato per lo sparse Bayesian infinite factor model, repliche sui dati simulati e misure di perfomance, con mixing functions
#mixing functions
log_posterior <- function(y, Lambda, eta, phi, delta, ps,
                          as, bs, df, ad1, bd1, ad2, bd2) {
  # 1) Log-verosimiglianza: Y | Lambda, eta, ps ~ N(eta %*% t(Lambda), diag(1/ps))
  mu   <- eta %*% t(Lambda)
  ll   <- sum(dnorm(y, mean = mu, sd = 1/sqrt(ps), log = TRUE))
  
  # 2) Prior su ps (Gamma(as, bs))
  lp_ps <- sum(dgamma(ps, shape = as, rate = bs, log = TRUE))
  
  # 3) Prior su Lambda | phi, delta
  tauh   <- cumprod(delta)
  Sd_inv <- sweep(phi, 2, tauh, "*")      # precision per colonna
  lp_L   <- sum(dnorm(Lambda, mean = 0,
                      sd = 1/sqrt(Sd_inv), log = TRUE))
  
  # 4) Prior su eta ~ N(0, I)
  lp_eta <- sum(dnorm(eta, mean = 0, sd = 1, log = TRUE))
  
  # 5) Prior su phi (Gamma(df/2, df/2))
  lp_phi <- sum(dgamma(phi, shape = df/2, rate = df/2, log = TRUE))
  
  # 6) Prior su delta[1] ~ Gamma(ad1, bd1)
  lp_d1  <- dgamma(delta[1], shape = ad1, rate = bd1, log = TRUE)
  #    e delta[h>1] ~ Gamma(ad2, bd2)
  lp_dh  <- sum(dgamma(delta[-1], shape = ad2, rate = bd2, log = TRUE))
  
  return(ll + lp_ps + lp_L + lp_eta + lp_phi + lp_d1 + lp_dh)
}
log_likelihood <- function(y, Lambda, eta,ps){
  # 1) Log-verosimiglianza: Y | Lambda, eta, ps ~ N(eta %*% t(Lambda), diag(1/ps))
  mu   <- eta %*% t(Lambda)
  ll   <- sum(dnorm(y, mean = mu, sd = 1/sqrt(ps), log = TRUE))
  return(ll)
}
n_iter <- 20000
thin <- 1
burn <- 5000
n_save <- (n_iter-burn)/ thin
    # scegliamo un valore di default come quello del paper
kinit <- rep(floor(log(p) * 3), times = rep)
#iperparametri
as    <- 1      
bs    <- 0.3    
df    <- 3      
ad1   <- 2.1     
bd1   <- 1      
ad2   <- 3.1      
bd2   <- 1   
alfa0 <- 1     
alfa1 <-  0.0005   
epsilon <- 1e-3 
prop    <- 1 

mserep  <- matrix(0, nrow = rep, ncol = 3)  # mse, bias assoluto (medio e massimo) nella stima di matrice di covarianza
mse1rep <- matrix(0, nrow = rep, ncol = 3)# come sopra, ma su scala originale
msperep <- matrix(0, nrow = rep, ncol = 3)
mseBrep <- matrix(0, nrow = rep, ncol = 3)
logpost <- numeric(n_iter)
loglike <- numeric(n_iter)

t0 <- Sys.time()

for (g in 1:rep) { 
  cat("start replicate", g, "\n")
  cat("--------------------\n")
 
 n_i <- 200
 dat_i <- dat[((g-1) * n_i+ 1):(g * n_i), ]   #estrazione righe
  
 #split da mettere per ottenere le predizioni per replica 
 prop_train <- 0.5                
 n_i       <- nrow(dat_i)
 n_train <- floor(prop_train * n_i)
 train_i <- sample(seq_len(n_i), size = n_train)
 y <- dat_i[train_i, , drop = FALSE]
 df_test  <- dat_i[-train_i, , drop = FALSE]
 df_test <-  scale(df_test, center= TRUE, scale = TRUE)
 
 
 
  M  <- colMeans(y)
  VY <- apply(y, 2, var)
   y <- sweep(y, 2, M, "-")             
  y <- sweep(y, 2, 1 / sqrt(VY), "*")    
  Ot1 <- Ot * (1 / sqrt( outer(VY, VY) ))
  
  
 
  # inizializzo contatore
  num <- 0
  
  k_star <- kinit[g]
  
  # --- 2) Inizializzazioni --- #
  p      <- ncol(y)    
  n      <- nrow(y)    
  
  ps     <- rgamma(p, shape = as, rate = bs)  
  Sigma  <- diag(1/ps)
  
  Lambda <- matrix(0, nrow = p, ncol = k_star)
  
  eta    <- matrix(rnorm(n * k_star), nrow = n, ncol = k_star)
  
  phi    <- matrix(rgamma(p * k_star,
                          shape = df/2,
                          rate  = df/2),
                   nrow = p, ncol = k_star)
  
  delta  <- c(rgamma(1, shape = ad1, rate = bd1),
              rgamma(k_star - 1, shape = ad2, rate = bd2))
  
  tauh    <- cumprod(delta)
  
  Plam   <- sweep(phi, 2, tauh, "*")
  
  
  Lambda_samples <- vector("list", n_save)
  sigma_samples <- matrix(NA, nrow = n_save, ncol = p)
  k_star_history <- numeric(n_save)
  # numero di fattori attraverso le iterazion
  mseout  <- matrix(0, nrow = n_save, ncol = 3)   #
  mse1out <- matrix(0, nrow = n_save, ncol = 3)  
  Omegaout  <- numeric(p^2)           # vettore di lunghezza p^2
  Omega1out <- numeric(p^2)           # v
  
  #GIBB SAMPLER#
  save_index <- 1
  for (iter in 1:n_iter) {  
    
    #step sample eta
    Lmsg   <- sweep(Lambda, 1, ps, "*")  
    Veta1  <- diag(k_star) + crossprod(Lmsg, Lambda) 
    U      <- chol(Veta1)    
    S      <- backsolve(U, diag(k_star))           
    Veta   <- S %*% t(S)
    Meta   <- y %*% Lmsg %*% Veta  
    eta    <- Meta + matrix(rnorm(n * k_star), nrow = n, ncol = k_star) %*% t(S) 
    
    
    #step sample lambda via rue and held
    eta2 <- crossprod(eta) 
    for (j in seq_len(p)) {
      Qlam   <- diag( Plam[j, ] ) + ps[j] * eta2 
      blam   <- ps[j] * crossprod(eta, y[, j])  # k×
      Llam   <- t(chol(Qlam))            
      zlam   <- rnorm(ncol(eta2))     
      vlam   <- forwardsolve(Llam,      blam) # Llam v = blam
      mlam   <- backsolve( t(Llam),     vlam) # Ll
      ylam   <- backsolve( t(Llam),forwardsolve(Llam, zlam) ) 
      Lambda[j, ] <- as.numeric( mlam + ylam )
    }
    
    
    # --- 1) Update phi -------------------------------------------
    phi     <- matrix(
      rgamma(p * k_star, shape =  df/2 + 0.5, rate = df/2 + sweep(Lambda^2, 2, tauh, "*")/2 ),
      nrow = p, ncol = k_star)
    
    
    # ---  Update delta e tauh ----------------------------------
    mat <- phi * (Lambda^2)   # matrice p × k_star
    
    # --- 1) aggiorno delta[1] ---
    ad1_post <- ad1 + 0.5 * p * k_star
    bd1_post <- bd1 + 0.5 * (1 / delta[1]) * sum(tauh * colSums(mat))
    delta[1] <- rgamma(1, shape = ad1_post, rate = bd1_post)
    tauh      <- cumprod(delta)   # aggiorno τ
    
    # --- 2) aggiorno delta[h] per h = 2..k_star ---
    for (h in 2:k_star) {
      ad_h <- ad2 + 0.5 * p * (k_star - h + 1)
      bd_h <- bd2 + 0.5 * (1 / delta[h]) * 
        sum( tauh[h:k_star] * colSums(mat[, h:k_star, drop = FALSE]) )
      delta[h] <- rgamma(1, shape = ad_h, rate = bd_h)
      tauh      <- cumprod(delta)   # riaggiorno τ ogni volta
    }
    
    # --- 3) Update Sigma (residual precision) --------------------
    Ytil <- y - eta %*% t(Lambda)
    ps      <- rgamma(p, shape = as + 0.5 * n, rate = bs + 0.5 * colSums(Ytil^2)  )
    Sigma   <- diag(1 / ps)
    
    #update precision parameter
    Plam <- sweep(phi,2 , tauh ,"*")
    
    # Calcola e salva la log-posterior
    logpost[iter] <- log_posterior(
      y, Lambda, eta, phi, delta, ps,
      as, bs, df, ad1, bd1, ad2, bd2
    )
     # Calcola e salva la log likelihood
    loglike[iter] <- log_likelihood(
      y, Lambda,eta,ps)
    
    #parametri per k adattivo
    rho_t <- 1/ exp(alfa0 + alfa1 * iter)
    uu <- runif(1)
    lind <- colSums(abs(Lambda) < epsilon) / p   # proporzione di zero per colonna
    vec  <- lind >= prop   #TRUE = colonna con zeri
    num  <- sum(vec) 
    
    # k adattiva
    if (iter > 20 && uu < rho_t) {
      if (num == 0 &&  all(lind < 0.995)) {
        k_star   <- k_star + 1
        Lambda   <- cbind(Lambda, rep(0, p))
        eta      <- cbind(eta,    rnorm(n))
        phi      <- cbind(phi,    rgamma(p, shape = df/2, rate = df/2))
        delta <- c(delta, rgamma(1,ad2,bd2))
        tauh <-exp(cumsum(log (delta)))
        Plam <- sweep(phi,2 , tauh ,"*")
      }
      else if (num > 0) {
        nonzero <- which(!vec)           
        k_star <- max(length(nonzero), 1)
        Lambda   <- Lambda[, nonzero, drop = FALSE]
        eta      <- eta[,    nonzero, drop = FALSE]
        phi      <- phi[,    nonzero, drop = FALSE]
        delta    <- delta[  nonzero]
        tauh <-exp(cumsum(log (delta)))
        Plam <- sweep(phi, 2 , tauh,"*")
      }
    } 
    
    # Salvataggio dei campioni
    
     if (iter %% thin == 0 && iter > burn) {
      Lambda_samples[[save_index]] <- Lambda
       sigma_samples[save_index, ] <- diag(Sigma)
       k_star_history[save_index] <- k_star
       save_index <- save_index + 1
        Omega  <- Lambda %*% t(Lambda) + Sigma
        Omega1 <- Omega * sqrt( outer(VY, VY) )
        Omegaout  <- Omegaout  + as.vector(Omega)  / n_save
        Omega1out <- Omega1out + as.vector(Omega1) / n_save
     }
    
    if (iter %% 1000 == 0) {
      cat("Iterazione:", iter, "k_star =", k_star, "\n")
    }   
  }
  
  # ---- misure di sintesi specifiche per la replica ----
  
  #1. mse on omega
  {
  errcov  <- Omegaout  - as.vector(Ot1)
  err1cov <- Omega1out - as.vector(Ot)
  mserep[g, ]  <- c(mean(errcov^2), mean(abs(errcov)),  max(abs(errcov)))
  mse1rep[g, ] <- c(mean(err1cov^2), mean(abs(err1cov)), max(abs(err1cov)))
  }
  
  #2. mse on prediction
  {
    #i. divisione in dipendent e predictor
    y_train <- y[,1]
    x_train <- y[,-1]
    y_test <- df_test[,1]
    x_test <- df_test[,-1]
    #ii. calcolo dei beta
    T     <- length(Lambda_samples)
    step  <- 50
    sel   <- seq(1, T, by = step) 
    Beta_samples <- matrix(NA, nrow = T/step, ncol = p-1)
    
    pb <- txtProgressBar(min = 0, max = T/step, style = 3)
    for (i in seq_along(sel)){
      Lambda_t   <- Lambda_samples[[i]]    # p × k_t
      psi_t <- sigma_samples[i, ]      # length p
      Omega_t  <- Lambda_t %*% t(Lambda_t) + diag(psi_t) 
      omega_xz_t <- Omega_t[2:p, 1]
      omega_xx_t <- Omega_t[-1,-1]
      Beta_samples[i, ] <- as.vector(solve(omega_xx_t) %*% omega_xz_t)
      setTxtProgressBar(pb, i) }
    
    close(pb)
    beta_map <- colMeans(Beta_samples) 
    
    #iii.calcolo predizioni e salvataggio mspe aape mape
    pred_test  <- Beta_samples %*% t(x_test)
    mean_pred_test  <- colMeans(pred_test)
    
    errs <- y_test-mean_pred_test
    msperep[g, ]  <- c(mean(errs^2), mean(abs(errs)),  max(abs(errs)))
  } 
  
  #3. mse on beta 
  {
    #beta TRUE
    Oxx <- Ot[-1,-1]
    Ozx <- Ot[2:p,1]
    beta_true <- solve(Oxx) %*% Ozx
    
    errb <- beta_map - beta_true
    
    mseBrep[g,] <- c(mean(errb^2),mean(abs(errb)), max(abs(errb)))
  } 
  
  cat("end replicate", g, "\n")
  cat("--------------------\n")
  }
    
t <- Sys.time()-t0
t  

#riassunti x replica
mse <- c(mean(mserep[,1]), min(mserep[,1]),max(mserep[,1]))*10^2
avgbias <- c(mean(mserep[,2]), min(mserep[,2]),max(mserep[,2]))*10^2
maxbias<- c(mean(mserep[,3]), min(mserep[,3]),max(mserep[,3]))*10^2
data.frame(mse = mse, avgbias = avgbias, maxbias = maxbias)

mspe <- c(mean(msperep[,1]), min(msperep[,1]),max(msperep[,1]))
aape <- c(mean(msperep[,2]), min(msperep[,2]),max(msperep[,2]))
mape <- c(mean(msperep[,3]), min(msperep[,3]),max(msperep[,3]))
data.frame(mspe = mspe, aape = aape, mape = mape)

mseb <- c(mean(mseBrep[,1]))*10^3
aab <-c(mean(mseBrep[,2]))*10^3
mab<-c(mean(mseBrep[,3]))*10^3
data.frame(mseb = mseb, aab = aab, mab = mab)
